{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a85ad75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "from typing import List, Tuple\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e32815",
   "metadata": {},
   "source": [
    "# Tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21f1507d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceTokenizer:\n",
    "    def __init__(self):\n",
    "        self.VOCABULARY = {\n",
    "            \"A\": 1,\n",
    "            \"U\": 2,\n",
    "            \"C\": 3,\n",
    "            \"G\": 4,\n",
    "        }\n",
    "        self.INVERTED_VOCABULARY = {self.VOCABULARY[i]: i for i in self.VOCABULARY}\n",
    "\n",
    "\n",
    "    def tokenize(self, sequence: str) -> torch.tensor:\n",
    "        return torch.tensor([self.VOCABULARY[i] for i in sequence], dtype=torch.long)\n",
    "    \n",
    "    def detokenize(self, tokens: torch.tensor) -> str:\n",
    "        return \"\".join([self.INVERTED_VOCABULARY[i] for i in tokens.tolist()])\n",
    "    \n",
    "class StructureTokenizer:\n",
    "    def __init__(self):\n",
    "        self.VOCABULARY = {\n",
    "            \".\": 0,\n",
    "            \"(\": 1,\n",
    "            \")\": 2,\n",
    "            \"[\": 3,\n",
    "            \"]\": 4,\n",
    "            \"{\": 5,\n",
    "            \"}\": 6\n",
    "        }\n",
    "        self.INVERTED_VOCABULARY = {self.VOCABULARY[i]: i for i in self.VOCABULARY}\n",
    "\n",
    "\n",
    "    def tokenize(self, structure: str) -> torch.tensor:\n",
    "        return torch.tensor([self.VOCABULARY[i] for i in structure], dtype=torch.long)\n",
    "    \n",
    "    def detokenize(self, tokens: torch.tensor) -> str:\n",
    "        return \"\".join([self.INVERTED_VOCABULARY[i] for i in tokens.tolist()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08875949",
   "metadata": {},
   "source": [
    "# Prepare dataset\n",
    "instead of predicting sequence it predicts pairwise interaction matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f7e74de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNADataset(Dataset):\n",
    "    def __init__(self, path: str, indices: List[int]):\n",
    "        \"\"\"path: path to .csv file with sequences and structures\"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.data = pd.read_csv(path)\n",
    "        self.data = self.data.iloc[indices].reset_index(drop=True)\n",
    "\n",
    "        self.sequence_tokenizer = SequenceTokenizer()\n",
    "        self.structure_tokenizer = StructureTokenizer()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        row = self.data.iloc[index]\n",
    "        sequence = row[\"sequence\"]\n",
    "        tokenized_sequence = self.sequence_tokenizer.tokenize(sequence)\n",
    "        structure = row[\"structure\"]\n",
    "        tokenized_structure = self.structure_tokenizer.tokenize(structure)\n",
    "        \n",
    "        return sequence, tokenized_sequence, structure, tokenized_structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cde52742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add this new cell after imports\n",
    "def collate_fn(batch):\n",
    "    \"\"\"Custom collate function to pad variable-length sequences\"\"\"\n",
    "    sequences, tokenized_seqs, structures, interaction_matrices = zip(*batch)\n",
    "    \n",
    "    # Find max length in this batch\n",
    "    max_len = max(len(seq) for seq in tokenized_seqs)\n",
    "    \n",
    "    # Pad tokenized sequences\n",
    "    padded_seqs = []\n",
    "    padding_masks = []\n",
    "    padded_matrices = []\n",
    "    \n",
    "    for tokenized_seq, interaction_matrix in zip(tokenized_seqs, interaction_matrices):\n",
    "        seq_len = len(tokenized_seq)\n",
    "        \n",
    "        # Pad sequence (0 is pad_idx)\n",
    "        padded_seq = torch.cat([\n",
    "            tokenized_seq,\n",
    "            torch.zeros(max_len - seq_len, dtype=torch.long)\n",
    "        ])\n",
    "        padded_seqs.append(padded_seq)\n",
    "        \n",
    "        # Create padding mask (True for padded positions)\n",
    "        mask = torch.cat([\n",
    "            torch.zeros(seq_len, dtype=torch.bool),\n",
    "            torch.ones(max_len - seq_len, dtype=torch.bool)\n",
    "        ])\n",
    "        padding_masks.append(mask)\n",
    "        \n",
    "        # Pad interaction matrix\n",
    "        padded_matrix = torch.zeros(max_len, max_len, dtype=torch.bfloat16)\n",
    "        padded_matrix[:seq_len, :seq_len] = interaction_matrix\n",
    "        padded_matrices.append(padded_matrix)\n",
    "    \n",
    "    return (\n",
    "        sequences,\n",
    "        torch.stack(padded_seqs),\n",
    "        structures,\n",
    "        torch.stack(padded_matrices),\n",
    "        torch.stack(padding_masks)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9709413b",
   "metadata": {},
   "source": [
    "# Create model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1dc1ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class transformerRNA(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        hidden_dim: int=1000, \n",
    "        num_transformer_layers: int=10, \n",
    "        n_head: int=8, \n",
    "        dropout: float=0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # output (L, H)\n",
    "        self.embedding = nn.Embedding(num_embeddings=5, embedding_dim=hidden_dim, padding_idx=0)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=hidden_dim,\n",
    "            nhead=n_head,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.encoder = nn.TransformerEncoder(\n",
    "            encoder_layer=encoder_layer,\n",
    "            num_layers=num_transformer_layers\n",
    "        )\n",
    "\n",
    "        self.output_head = nn.Linear(hidden_dim, 7)\n",
    "\n",
    "    def forward(self, x, src_key_padding_mask=None):\n",
    "        x = self.embedding(x)\n",
    "        # (L, H)\n",
    "        x = self.encoder(x, src_key_padding_mask=src_key_padding_mask)\n",
    "        # (L, H)\n",
    "        x = self.output_head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d46bec4",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5dce34a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNATrainer:\n",
    "    def __init__(self, model: transformerRNA, device: torch.device):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters())\n",
    "\n",
    "    def train_epoch(self, train_dataloader: torch.utils.data.DataLoader) -> float:\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for sequence, tokenized_sequence, structure, tokenized_structure in tqdm(train_dataloader, desc=\"Training\"):\n",
    "            tokenized_sequence = tokenized_sequence.to(self.device)\n",
    "            tokenized_structure = tokenized_structure.to(self.device)\n",
    "            # print(tokenized_sequence)\n",
    "            # padding_mask = padding_mask.to(self.device)\n",
    "\n",
    "            out_logits = self.model(tokenized_sequence)\n",
    "\n",
    "            # print(out_logits.shape)\n",
    "\n",
    "            loss = self.criterion(out_logits.view(-1, 7), tokenized_structure.view(-1))\n",
    "\n",
    "            # valid_mask = (~padding_mask).unsqueeze(-1) & (~padding_mask).unsqueeze(-2)\n",
    "            # loss = (loss * valid_mask).sum() / valid_mask.sum()\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_losss = total_loss / len(train_dataloader)\n",
    "        return avg_losss\n",
    "\n",
    "    # def test_model(self, test_loader)\n",
    "    # TODO: test model with reconstructed structure from interaction matrix\n",
    "\n",
    "    def train(\n",
    "        self, \n",
    "        train_dataloader: torch.utils.data.DataLoader, \n",
    "        test_dataloader: torch.utils.data.DataLoader,\n",
    "        num_epochs: int\n",
    "    ) -> None:\n",
    "        for epoch in range(num_epochs):\n",
    "            avg_loss = self.train_epoch(train_dataloader)\n",
    "            print(f\"Epoch {epoch} current loss: {avg_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b7bb4f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "93b8e352",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SIZE = 11500\n",
    "TEST_SIZE = 1646\n",
    "\n",
    "train_indices = list(range(TRAIN_SIZE))\n",
    "test_indices = list(range(TRAIN_SIZE, TRAIN_SIZE+TEST_SIZE))\n",
    "\n",
    "train_dataset = RNADataset(\"rna_dataset.csv\", train_indices)\n",
    "test_dataset = RNADataset(\"rna_dataset.csv\", test_indices)\n",
    "\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    shuffle=True,\n",
    "    batch_size=1,          # try 16–64; tune to your VRAM\n",
    "    # collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    shuffle=False,\n",
    "    batch_size=1,\n",
    "    # collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1c1879d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plague/miniconda3/envs/torch312/lib/python3.12/site-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 11500/11500 [00:31<00:00, 366.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 current loss: 1.0229959918156915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 11500/11500 [00:32<00:00, 354.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 current loss: 1.0179621970083403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 227/11500 [00:00<00:31, 353.60it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m model = model.to(device)\n\u001b[32m      3\u001b[39m trainer = RNATrainer(model, device)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 48\u001b[39m, in \u001b[36mRNATrainer.train\u001b[39m\u001b[34m(self, train_dataloader, test_dataloader, num_epochs)\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtrain\u001b[39m(\n\u001b[32m     42\u001b[39m     \u001b[38;5;28mself\u001b[39m, \n\u001b[32m     43\u001b[39m     train_dataloader: torch.utils.data.DataLoader, \n\u001b[32m     44\u001b[39m     test_dataloader: torch.utils.data.DataLoader,\n\u001b[32m     45\u001b[39m     num_epochs: \u001b[38;5;28mint\u001b[39m\n\u001b[32m     46\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m         avg_loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m current loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 29\u001b[39m, in \u001b[36mRNATrainer.train_epoch\u001b[39m\u001b[34m(self, train_dataloader)\u001b[39m\n\u001b[32m     24\u001b[39m loss = \u001b[38;5;28mself\u001b[39m.criterion(out_logits.view(-\u001b[32m1\u001b[39m, \u001b[32m7\u001b[39m), tokenized_structure.view(-\u001b[32m1\u001b[39m))\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# valid_mask = (~padding_mask).unsqueeze(-1) & (~padding_mask).unsqueeze(-2)\u001b[39;00m\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# loss = (loss * valid_mask).sum() / valid_mask.sum()\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m loss.backward()\n\u001b[32m     31\u001b[39m \u001b[38;5;28mself\u001b[39m.optimizer.step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/torch312/lib/python3.12/site-packages/torch/_compile.py:41\u001b[39m, in \u001b[36m_disable_dynamo.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[33;03mThis API should be only used inside torch, external users should still use\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[33;03mtorch._dynamo.disable. The main goal of this API is to avoid circular\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     37\u001b[39m \u001b[33;03mthe invocation of the decorated function.\u001b[39;00m\n\u001b[32m     38\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     \u001b[38;5;129m@functools\u001b[39m.wraps(fn)\n\u001b[32m     42\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minner\u001b[39m(*args: _P.args, **kwargs: _P.kwargs) -> _T:\n\u001b[32m     43\u001b[39m         \u001b[38;5;66;03m# cache this on the first invocation to avoid adding too much overhead.\u001b[39;00m\n\u001b[32m     44\u001b[39m         disable_fn = \u001b[38;5;28mgetattr\u001b[39m(fn, \u001b[33m\"\u001b[39m\u001b[33m__dynamo_disable\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     45\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m disable_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "model = transformerRNA(hidden_dim=50, num_transformer_layers=2, n_head=1)\n",
    "model = model.to(device)\n",
    "trainer = RNATrainer(model, device)\n",
    "trainer.train(train_dataloader, test_dataloader, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efdf266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters: 25,484,288\n",
      "Model memory: 97.21 MB\n"
     ]
    }
   ],
   "source": [
    "def get_model_memory(model):\n",
    "    \"\"\"Calculate model memory in MB\"\"\"\n",
    "    param_size = sum(p.nelement() * p.element_size() for p in model.parameters())\n",
    "    buffer_size = sum(b.nelement() * b.element_size() for b in model.buffers())\n",
    "    total_size_mb = (param_size + buffer_size) / 1024**2\n",
    "    return total_size_mb\n",
    "\n",
    "# Check your current model\n",
    "model_memory = get_model_memory(model)\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"Model memory: {model_memory:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a50af0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def generate_heatmap(matrix) -> None:\n",
    "    if isinstance(matrix, torch.Tensor):\n",
    "        matrix = matrix.float().cpu().numpy()\n",
    "    sns.heatmap(matrix)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c502094b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 84])\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2,\n",
      "        2, 2, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0])\n",
      "torch.Size([1, 84, 7])\n",
      "tensor([[ 1.3313,  0.9573,  0.8748, -3.4629, -3.6553, -7.6936, -7.8399],\n",
      "        [ 1.2822,  0.8976,  0.9294, -3.5669, -3.4107, -7.5125, -8.0027],\n",
      "        [ 1.2822,  0.8976,  0.9294, -3.5669, -3.4107, -7.5125, -8.0027],\n",
      "        [ 1.5409,  0.8641,  0.7817, -3.4292, -3.6989, -7.8867, -7.9812],\n",
      "        [ 1.5409,  0.8641,  0.7817, -3.4292, -3.6989, -7.8867, -7.9812],\n",
      "        [ 1.2822,  0.8976,  0.9294, -3.5669, -3.4107, -7.5125, -8.0027],\n",
      "        [ 1.3313,  0.9573,  0.8748, -3.4629, -3.6553, -7.6936, -7.8399],\n",
      "        [ 1.5409,  0.8641,  0.7817, -3.4292, -3.6989, -7.8867, -7.9812],\n",
      "        [ 1.3313,  0.9573,  0.8748, -3.4629, -3.6553, -7.6936, -7.8399],\n",
      "        [ 2.0262,  0.5233,  0.6894, -4.4981, -4.1539, -9.3515, -8.5762],\n",
      "        [ 1.5409,  0.8641,  0.7817, -3.4292, -3.6989, -7.8867, -7.9812],\n",
      "        [ 1.2822,  0.8976,  0.9294, -3.5669, -3.4107, -7.5125, -8.0027],\n",
      "        [ 1.3313,  0.9573,  0.8748, -3.4629, -3.6553, -7.6936, -7.8399],\n",
      "        [ 1.3313,  0.9573,  0.8748, -3.4629, -3.6553, -7.6936, -7.8399],\n",
      "        [ 2.0262,  0.5233,  0.6894, -4.4981, -4.1539, -9.3515, -8.5762],\n",
      "        [ 2.0262,  0.5233,  0.6894, -4.4981, -4.1539, -9.3515, -8.5762],\n",
      "        [ 1.5409,  0.8641,  0.7817, -3.4292, -3.6989, -7.8867, -7.9812],\n",
      "        [ 1.3313,  0.9573,  0.8748, -3.4629, -3.6553, -7.6936, -7.8399],\n",
      "        [ 1.3313,  0.9573,  0.8748, -3.4629, -3.6553, -7.6936, -7.8399],\n",
      "        [ 1.5409,  0.8641,  0.7817, -3.4292, -3.6989, -7.8867, -7.9812],\n",
      "        [ 2.0262,  0.5233,  0.6894, -4.4981, -4.1539, -9.3515, -8.5762],\n",
      "        [ 1.3313,  0.9573,  0.8748, -3.4629, -3.6553, -7.6936, -7.8399],\n",
      "        [ 2.0262,  0.5233,  0.6894, -4.4981, -4.1539, -9.3515, -8.5762],\n",
      "        [ 1.3313,  0.9573,  0.8748, -3.4629, -3.6553, -7.6936, -7.8399],\n",
      "        [ 2.0262,  0.5233,  0.6894, -4.4981, -4.1539, -9.3515, -8.5762],\n",
      "        [ 1.5409,  0.8641,  0.7817, -3.4292, -3.6989, -7.8867, -7.9812],\n",
      "        [ 1.2822,  0.8976,  0.9294, -3.5669, -3.4107, -7.5125, -8.0027],\n",
      "        [ 1.2822,  0.8976,  0.9294, -3.5669, -3.4107, -7.5125, -8.0027],\n",
      "        [ 1.5409,  0.8641,  0.7817, -3.4292, -3.6989, -7.8867, -7.9812],\n",
      "        [ 1.3313,  0.9573,  0.8748, -3.4629, -3.6553, -7.6936, -7.8399],\n",
      "        [ 1.3313,  0.9573,  0.8748, -3.4629, -3.6553, -7.6936, -7.8399],\n",
      "        [ 1.5409,  0.8641,  0.7817, -3.4292, -3.6989, -7.8867, -7.9812],\n",
      "        [ 1.2822,  0.8976,  0.9294, -3.5669, -3.4107, -7.5125, -8.0027],\n",
      "        [ 1.5409,  0.8641,  0.7817, -3.4292, -3.6989, -7.8867, -7.9812],\n",
      "        [ 1.5409,  0.8641,  0.7817, -3.4292, -3.6989, -7.8867, -7.9812],\n",
      "        [ 2.0262,  0.5233,  0.6894, -4.4981, -4.1539, -9.3515, -8.5762],\n",
      "        [ 1.3313,  0.9573,  0.8748, -3.4629, -3.6553, -7.6936, -7.8399],\n",
      "        [ 1.3313,  0.9573,  0.8748, -3.4629, -3.6553, -7.6936, -7.8399],\n",
      "        [ 2.0262,  0.5233,  0.6894, -4.4981, -4.1539, -9.3515, -8.5762],\n",
      "        [ 2.0262,  0.5233,  0.6894, -4.4981, -4.1539, -9.3515, -8.5762],\n",
      "        [ 1.2822,  0.8976,  0.9294, -3.5669, -3.4107, -7.5125, -8.0027],\n",
      "        [ 1.2822,  0.8976,  0.9294, -3.5669, -3.4107, -7.5125, -8.0027],\n",
      "        [ 2.0262,  0.5233,  0.6894, -4.4981, -4.1539, -9.3515, -8.5762],\n",
      "        [ 1.3313,  0.9573,  0.8748, -3.4629, -3.6553, -7.6936, -7.8399],\n",
      "        [ 1.2822,  0.8976,  0.9294, -3.5669, -3.4107, -7.5125, -8.0027],\n",
      "        [ 1.5409,  0.8641,  0.7817, -3.4292, -3.6989, -7.8867, -7.9812],\n",
      "        [ 1.3313,  0.9573,  0.8748, -3.4629, -3.6553, -7.6936, -7.8399],\n",
      "        [ 1.2822,  0.8976,  0.9294, -3.5669, -3.4107, -7.5125, -8.0027],\n",
      "        [ 1.5409,  0.8641,  0.7817, -3.4292, -3.6989, -7.8867, -7.9812],\n",
      "        [ 1.3313,  0.9573,  0.8748, -3.4629, -3.6553, -7.6936, -7.8399],\n",
      "        [ 2.0262,  0.5233,  0.6894, -4.4981, -4.1539, -9.3515, -8.5762],\n",
      "        [ 2.0262,  0.5233,  0.6894, -4.4981, -4.1539, -9.3515, -8.5762],\n",
      "        [ 2.0262,  0.5233,  0.6894, -4.4981, -4.1539, -9.3515, -8.5762],\n",
      "        [ 1.3313,  0.9573,  0.8748, -3.4629, -3.6553, -7.6936, -7.8399],\n",
      "        [ 1.3313,  0.9573,  0.8748, -3.4629, -3.6553, -7.6936, -7.8399],\n",
      "        [ 1.2822,  0.8976,  0.9294, -3.5669, -3.4107, -7.5125, -8.0027],\n",
      "        [ 1.3313,  0.9573,  0.8748, -3.4629, -3.6553, -7.6936, -7.8399],\n",
      "        [ 1.3313,  0.9573,  0.8748, -3.4629, -3.6553, -7.6936, -7.8399],\n",
      "        [ 1.2822,  0.8976,  0.9294, -3.5669, -3.4107, -7.5125, -8.0027],\n",
      "        [ 1.3313,  0.9573,  0.8748, -3.4629, -3.6553, -7.6936, -7.8399],\n",
      "        [ 1.3313,  0.9573,  0.8748, -3.4629, -3.6553, -7.6936, -7.8399],\n",
      "        [ 1.5409,  0.8641,  0.7817, -3.4292, -3.6989, -7.8867, -7.9812],\n",
      "        [ 1.5409,  0.8641,  0.7817, -3.4292, -3.6989, -7.8867, -7.9812],\n",
      "        [ 1.2822,  0.8976,  0.9294, -3.5669, -3.4107, -7.5125, -8.0027],\n",
      "        [ 2.0262,  0.5233,  0.6894, -4.4981, -4.1539, -9.3515, -8.5762],\n",
      "        [ 2.0262,  0.5233,  0.6894, -4.4981, -4.1539, -9.3515, -8.5762],\n",
      "        [ 2.0262,  0.5233,  0.6894, -4.4981, -4.1539, -9.3515, -8.5762],\n",
      "        [ 1.5409,  0.8641,  0.7817, -3.4292, -3.6989, -7.8867, -7.9812],\n",
      "        [ 1.2822,  0.8976,  0.9294, -3.5669, -3.4107, -7.5125, -8.0027],\n",
      "        [ 1.2822,  0.8976,  0.9294, -3.5669, -3.4107, -7.5125, -8.0027],\n",
      "        [ 1.3313,  0.9573,  0.8748, -3.4629, -3.6553, -7.6936, -7.8399],\n",
      "        [ 1.2822,  0.8976,  0.9294, -3.5669, -3.4107, -7.5125, -8.0027],\n",
      "        [ 1.2822,  0.8976,  0.9294, -3.5669, -3.4107, -7.5125, -8.0027],\n",
      "        [ 1.2822,  0.8976,  0.9294, -3.5669, -3.4107, -7.5125, -8.0027],\n",
      "        [ 1.3313,  0.9573,  0.8748, -3.4629, -3.6553, -7.6936, -7.8399],\n",
      "        [ 2.0262,  0.5233,  0.6894, -4.4981, -4.1539, -9.3515, -8.5762],\n",
      "        [ 2.0262,  0.5233,  0.6894, -4.4981, -4.1539, -9.3515, -8.5762],\n",
      "        [ 1.3313,  0.9573,  0.8748, -3.4629, -3.6553, -7.6936, -7.8399],\n",
      "        [ 1.3313,  0.9573,  0.8748, -3.4629, -3.6553, -7.6936, -7.8399],\n",
      "        [ 1.2822,  0.8976,  0.9294, -3.5669, -3.4107, -7.5125, -8.0027],\n",
      "        [ 2.0262,  0.5233,  0.6894, -4.4981, -4.1539, -9.3515, -8.5762],\n",
      "        [ 1.2822,  0.8976,  0.9294, -3.5669, -3.4107, -7.5125, -8.0027],\n",
      "        [ 1.2822,  0.8976,  0.9294, -3.5669, -3.4107, -7.5125, -8.0027],\n",
      "        [ 2.0262,  0.5233,  0.6894, -4.4981, -4.1539, -9.3515, -8.5762]],\n",
      "       device='cuda:0')\n",
      "torch.Size([84, 7])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for sequence, tokenized_sequence, structure, tokenized_structure in test_dataloader:\n",
    "        print(tokenized_structure.shape)\n",
    "\n",
    "\n",
    "        tokenized_structure = tokenized_structure.view(-1)\n",
    "        print(tokenized_structure)\n",
    "        tokenized_sequence = tokenized_sequence.to(device)\n",
    "        out_logits = model(tokenized_sequence)\n",
    "        print(out_logits.shape)\n",
    "        out_logits = out_logits.view(-1, 7)\n",
    "        print(out_logits)\n",
    "        print(out_logits.shape)\n",
    "        # out_logits = torch.sigmoid(out_logits)\n",
    "        # print(out_logits)\n",
    "\n",
    "        # generate_heatmap(interaction_matrix[0])\n",
    "        # generate_heatmap(out_logits[0])\n",
    "\n",
    "\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f6f122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 4, 3], dtype=torch.int8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.sequence_tokenizer.tokenize(\"AUGC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4570226c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
