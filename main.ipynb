{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a85ad75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "from typing import List, Tuple\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e32815",
   "metadata": {},
   "source": [
    "# Tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21f1507d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceTokenizer:\n",
    "    def __init__(self):\n",
    "        self.VOCABULARY = {\n",
    "            \"A\": 1,\n",
    "            \"U\": 2,\n",
    "            \"C\": 3,\n",
    "            \"G\": 4,\n",
    "        }\n",
    "        self.INVERTED_VOCABULARY = {self.VOCABULARY[i]: i for i in self.VOCABULARY}\n",
    "\n",
    "\n",
    "    def tokenize(self, sequence: str) -> torch.tensor:\n",
    "        return torch.tensor([self.VOCABULARY[i] for i in sequence], dtype=torch.long)\n",
    "    \n",
    "    def detokenize(self, tokens: torch.tensor) -> str:\n",
    "        return \"\".join([self.INVERTED_VOCABULARY[i] for i in tokens.tolist()])\n",
    "    \n",
    "class StructureTokenizer:\n",
    "    def __init__(self):\n",
    "        self.VOCABULARY = {\n",
    "            \"(\": 1,\n",
    "            \")\": 2,\n",
    "            \"[\": 3,\n",
    "            \"]\": 4,\n",
    "            \"{\": 5,\n",
    "            \"}\": 6,\n",
    "            \".\": 7,\n",
    "        }\n",
    "        self.INVERTED_VOCABULARY = {self.VOCABULARY[i]: i for i in self.VOCABULARY}\n",
    "\n",
    "\n",
    "    def tokenize(self, structure: str) -> torch.tensor:\n",
    "        return torch.tensor([self.VOCABULARY[i] for i in structure], dtype=torch.long)\n",
    "    \n",
    "    def detokenize(self, tokens: torch.tensor) -> str:\n",
    "        return \"\".join([self.INVERTED_VOCABULARY[i] for i in tokens.tolist()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08875949",
   "metadata": {},
   "source": [
    "# Prepare dataset\n",
    "instead of predicting sequence it predicts pairwise interaction matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f7e74de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNADataset(Dataset):\n",
    "    def __init__(self, path: str, indices: List[int]):\n",
    "        \"\"\"path: path to .csv file with sequences and structures\"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.data = pd.read_csv(path)\n",
    "        self.data = self.data.iloc[indices].reset_index(drop=True)\n",
    "\n",
    "        self.sequence_tokenizer = SequenceTokenizer()\n",
    "        self.structure_tokenizer = StructureTokenizer()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        row = self.data.iloc[index]\n",
    "        sequence = row[\"sequence\"]\n",
    "        tokenized_sequence = self.sequence_tokenizer.tokenize(sequence)\n",
    "        structure = row[\"structure\"]\n",
    "        tokenized_structure = self.structure_tokenizer.tokenize(structure)\n",
    "        \n",
    "        return sequence, tokenized_sequence, structure, tokenized_structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cde52742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add this new cell after imports\n",
    "# def collate_fn(batch):\n",
    "#     \"\"\"Custom collate function to pad variable-length sequences\"\"\"\n",
    "#     sequences, tokenized_seqs, structures, interaction_matrices = zip(*batch)\n",
    "    \n",
    "#     # Find max length in this batch\n",
    "#     max_len = max(len(seq) for seq in tokenized_seqs)\n",
    "    \n",
    "#     # Pad tokenized sequences\n",
    "#     padded_seqs = []\n",
    "#     padding_masks = []\n",
    "#     padded_matrices = []\n",
    "    \n",
    "#     for tokenized_seq, interaction_matrix in zip(tokenized_seqs, interaction_matrices):\n",
    "#         seq_len = len(tokenized_seq)\n",
    "        \n",
    "#         # Pad sequence (0 is pad_idx)\n",
    "#         padded_seq = torch.cat([\n",
    "#             tokenized_seq,\n",
    "#             torch.zeros(max_len - seq_len, dtype=torch.long)\n",
    "#         ])\n",
    "#         padded_seqs.append(padded_seq)\n",
    "        \n",
    "#         # Create padding mask (True for padded positions)\n",
    "#         mask = torch.cat([\n",
    "#             torch.zeros(seq_len, dtype=torch.bool),\n",
    "#             torch.ones(max_len - seq_len, dtype=torch.bool)\n",
    "#         ])\n",
    "#         padding_masks.append(mask)\n",
    "        \n",
    "#         # Pad interaction matrix\n",
    "#         padded_matrix = torch.zeros(max_len, max_len, dtype=torch.bfloat16)\n",
    "#         padded_matrix[:seq_len, :seq_len] = interaction_matrix\n",
    "#         padded_matrices.append(padded_matrix)\n",
    "    \n",
    "#     return (\n",
    "#         sequences,\n",
    "#         torch.stack(padded_seqs),\n",
    "#         structures,\n",
    "#         torch.stack(padded_matrices),\n",
    "#         torch.stack(padding_masks)\n",
    "#     )\n",
    "\n",
    "def collate_fn(batch):\n",
    "    sequences, tokenized_seqs, structures, tokenized_structures = zip(*batch)\n",
    "    max_len = max(len(seq) for seq in tokenized_seqs)\n",
    "\n",
    "    padded_tokenized_sequences = []\n",
    "    padded_tokenized_structures = []\n",
    "\n",
    "    for tokenized_sequence, tokenized_structure in zip(tokenized_seqs, tokenized_structures):\n",
    "        sequence_lenght = len(tokenized_sequence)\n",
    "        padded_seq = torch.cat([\n",
    "            tokenized_sequence,\n",
    "            torch.zeros(max_len - sequence_lenght, dtype=torch.long)\n",
    "        ])\n",
    "        padded_structure = torch.cat([\n",
    "            tokenized_structure,\n",
    "            torch.zeros(max_len - sequence_lenght, dtype=torch.long)\n",
    "        ])\n",
    "        padded_tokenized_sequences.append(padded_seq)\n",
    "        padded_tokenized_structures.append(padded_structure)\n",
    "\n",
    "    padded_tokenized_sequences = torch.stack(padded_tokenized_sequences, dim=0)\n",
    "    padded_tokenized_structures = torch.stack(padded_tokenized_structures, dim=0)\n",
    "\n",
    "    return sequences, padded_tokenized_sequences, structures, padded_tokenized_structures\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9709413b",
   "metadata": {},
   "source": [
    "# Create model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1dc1ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class transformerRNA(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        hidden_dim: int=1000, \n",
    "        num_transformer_layers: int=10, \n",
    "        n_head: int=8, \n",
    "        dropout: float=0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # output (L, H)\n",
    "        self.embedding = nn.Embedding(num_embeddings=5, embedding_dim=hidden_dim, padding_idx=0)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=hidden_dim,\n",
    "            nhead=n_head,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.encoder = nn.TransformerEncoder(\n",
    "            encoder_layer=encoder_layer,\n",
    "            num_layers=num_transformer_layers\n",
    "        )\n",
    "\n",
    "        self.output_head = nn.Linear(hidden_dim, 8)\n",
    "\n",
    "    def forward(self, x, src_key_padding_mask=None):\n",
    "        padding_mask = (x == 0)\n",
    "        x = self.embedding(x)\n",
    "        # (L, H)\n",
    "        x = self.encoder(x, src_key_padding_mask=padding_mask)\n",
    "        # (L, H)\n",
    "        x = self.output_head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d46bec4",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5dce34a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNATrainer:\n",
    "    def __init__(self, model: transformerRNA, device: torch.device):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters())\n",
    "\n",
    "    def train_epoch(self, train_dataloader: torch.utils.data.DataLoader) -> float:\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for sequence, tokenized_sequence, structure, tokenized_structure in tqdm(train_dataloader, desc=\"Training\"):\n",
    "            tokenized_sequence = tokenized_sequence.to(self.device)\n",
    "            tokenized_structure = tokenized_structure.to(self.device)\n",
    "            # print(tokenized_sequence)\n",
    "            # padding_mask = padding_mask.to(self.device)\n",
    "\n",
    "            out_logits = self.model(tokenized_sequence)\n",
    "\n",
    "            # print(out_logits.shape)\n",
    "\n",
    "            loss = self.criterion(out_logits.view(-1, 8), tokenized_structure.view(-1))\n",
    "\n",
    "            # valid_mask = (~padding_mask).unsqueeze(-1) & (~padding_mask).unsqueeze(-2)\n",
    "            # loss = (loss * valid_mask).sum() / valid_mask.sum()\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_losss = total_loss / len(train_dataloader)\n",
    "        return avg_losss\n",
    "\n",
    "    # def test_model(self, test_loader)\n",
    "    # TODO: test model with reconstructed structure from interaction matrix\n",
    "\n",
    "    def train(\n",
    "        self, \n",
    "        train_dataloader: torch.utils.data.DataLoader, \n",
    "        test_dataloader: torch.utils.data.DataLoader,\n",
    "        num_epochs: int\n",
    "    ) -> None:\n",
    "        for epoch in range(num_epochs):\n",
    "            avg_loss = self.train_epoch(train_dataloader)\n",
    "            print(f\"Epoch {epoch} current loss: {avg_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7bb4f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93b8e352",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SIZE = 11500\n",
    "TEST_SIZE = 1646\n",
    "\n",
    "train_indices = list(range(TRAIN_SIZE))\n",
    "test_indices = list(range(TRAIN_SIZE, TRAIN_SIZE+TEST_SIZE))\n",
    "\n",
    "train_dataset = RNADataset(\"rna_dataset.csv\", train_indices)\n",
    "test_dataset = RNADataset(\"rna_dataset.csv\", test_indices)\n",
    "\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    shuffle=True,\n",
    "    batch_size=16,          # try 16–64; tune to your VRAM\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    shuffle=False,\n",
    "    batch_size=1,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c1879d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 719/719 [02:12<00:00,  5.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 current loss: 1.065320306842284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 719/719 [02:13<00:00,  5.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 current loss: 1.051601047393178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 719/719 [02:12<00:00,  5.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 current loss: 1.0505042228645676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 61/719 [00:11<02:04,  5.29it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m model = model.to(device)\n\u001b[32m      3\u001b[39m trainer = RNATrainer(model, device)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 48\u001b[39m, in \u001b[36mRNATrainer.train\u001b[39m\u001b[34m(self, train_dataloader, test_dataloader, num_epochs)\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtrain\u001b[39m(\n\u001b[32m     42\u001b[39m     \u001b[38;5;28mself\u001b[39m, \n\u001b[32m     43\u001b[39m     train_dataloader: torch.utils.data.DataLoader, \n\u001b[32m     44\u001b[39m     test_dataloader: torch.utils.data.DataLoader,\n\u001b[32m     45\u001b[39m     num_epochs: \u001b[38;5;28mint\u001b[39m\n\u001b[32m     46\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m         avg_loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m current loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 33\u001b[39m, in \u001b[36mRNATrainer.train_epoch\u001b[39m\u001b[34m(self, train_dataloader)\u001b[39m\n\u001b[32m     30\u001b[39m     loss.backward()\n\u001b[32m     31\u001b[39m     \u001b[38;5;28mself\u001b[39m.optimizer.step()\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m     total_loss += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m avg_losss = total_loss / \u001b[38;5;28mlen\u001b[39m(train_dataloader)\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m avg_losss\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "model = transformerRNA(hidden_dim=512, num_transformer_layers=8, n_head=8)\n",
    "model = model.to(device)\n",
    "trainer = RNATrainer(model, device)\n",
    "trainer.train(train_dataloader, test_dataloader, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3efdf266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters: 25,225,736\n",
      "Model memory: 96.23 MB\n"
     ]
    }
   ],
   "source": [
    "def get_model_memory(model):\n",
    "    \"\"\"Calculate model memory in MB\"\"\"\n",
    "    param_size = sum(p.nelement() * p.element_size() for p in model.parameters())\n",
    "    buffer_size = sum(b.nelement() * b.element_size() for b in model.buffers())\n",
    "    total_size_mb = (param_size + buffer_size) / 1024**2\n",
    "    return total_size_mb\n",
    "\n",
    "# Check your current model\n",
    "model_memory = get_model_memory(model)\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"Model memory: {model_memory:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a50af0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def generate_heatmap(matrix) -> None:\n",
    "    if isinstance(matrix, torch.Tensor):\n",
    "        matrix = matrix.float().cpu().numpy()\n",
    "    sns.heatmap(matrix)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c502094b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 84])\n",
      "tensor([[7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
      "         7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
      "         7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
      "         7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]], device='cuda:0')\n",
      "Predicted structure tokens: ....................................................................................\n",
      "Ground truth structure tokens: (((((((..(((...........))).(((((.......)))))............(((((.......))))))))))))....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plague/miniconda3/envs/torch312/lib/python3.12/site-packages/torch/nn/modules/transformer.py:515: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. We recommend specifying layout=torch.jagged when constructing a nested tensor, as this layout receives active development, has better operator coverage, and works with torch.compile. (Triggered internally at /pytorch/aten/src/ATen/NestedTensorImpl.cpp:178.)\n",
      "  output = torch._nested_tensor_from_mask(\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "detokenizer = StructureTokenizer()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for sequence, tokenized_sequence, structure, tokenized_structure in test_dataloader:\n",
    "        print(tokenized_structure.shape)\n",
    "\n",
    "\n",
    "        tokenized_structure = tokenized_structure.view(-1)\n",
    "        tokenized_sequence = tokenized_sequence.to(device)\n",
    "        out_logits = model(tokenized_sequence)\n",
    "        out_probs = torch.softmax(out_logits, dim=-1)\n",
    "        predicted_structure = torch.argmax(out_probs, dim=-1)\n",
    "        print(predicted_structure)\n",
    "        print(\"Predicted structure tokens:\", detokenizer.detokenize(predicted_structure[0]))\n",
    "        print(\"Ground truth structure tokens:\", structure[0])\n",
    "\n",
    "\n",
    "\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "44f6f122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 4, 3])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.sequence_tokenizer.tokenize(\"AUGC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4570226c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
